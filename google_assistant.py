# -*- coding: utf-8 -*-
"""Google Assistant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HscgFxMHE_8WhKpZJ_O_HZUHB3zaimZ-
"""

# Create a function for taking user input
# Create a function for getting chatgpt response
# Create a function for Text to speech

!pip install --upgrade openai

!pip install gTTS

from google.colab import userdata

from openai import OpenAI
client = OpenAI(
  api_key= userdata.get('api_key'),
)

from gtts import gTTS #Import Google Text to Speech
from IPython.display import Audio #Import Audio method from IPython's Display Class

def getUserInput():
  some_text = input('How can I help you ? ')
  return some_text

def askGPT():
    completion = client.chat.completions.create(
      model="gpt-3.5-turbo",
      messages=[
        {"role": "system", "content": "You are a general purpose chatbot"},
        {"role": "user", "content": getUserInput() }
      ]
    )
    response_from_chatGPT = completion.choices[0].message.content
    return response_from_chatGPT

def speakNow(content):
  tts = gTTS(content) #Provide the string to convert to speech
  tts.save('1.wav') #save the string converted to speech as a .wav file
  sound_file = '1.wav'
  Audio(sound_file, autoplay=True)

wanna_ask_more = 'y'

while wanna_ask_more == 'y':
  ans = askGPT()
  speakNow(ans)
  sound_file = '1.wav'
  Audio(sound_file, autoplay=True)
  print('-------------- ')
  wanna_ask_more= input("Wanna ask more questions ?? y/n - ")

!pip install speechrecognition

!pip install pyttsx3

!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg

!pip install pyaudio

import speech_recognition as sr
import pyttsx3

# Initialize the recognizer
r = sr.Recognizer()

# Function to convert text to
# speech
def SpeakText(command):

    # Initialize the engine
    engine = pyttsx3.init()
    engine.say(command)
    engine.runAndWait()

# while(1):

#     # Exception handling to handle
#     # exceptions at the runtime
#     try:

#         # use the microphone as source for input.
#         with sr.Microphone() as source2:

#             # wait for a second to let the recognizer
#             # adjust the energy threshold based on
#             # the surrounding noise level
#             r.adjust_for_ambient_noise(source2, duration=0.2)

#             #listens for the user's input
#             audio2 = r.listen(source2)

#             # Using google to recognize audio
#             MyText = r.recognize_google(audio2)
#             MyText = MyText.lower()

#             print("Did you say ",MyText)
#             SpeakText(MyText)

#     except sr.RequestError as e:
#         print("Could not request results; {0}".format(e))

#     except sr.UnknownValueError:
#         print("unknown error occurred")

# all imports
from io import BytesIO
from base64 import b64decode
from google.colab import output
from IPython.display import Javascript

RECORD = """
const sleep  = time => new Promise(resolve => setTimeout(resolve, time))
const b2text = blob => new Promise(resolve => {
  const reader = new FileReader()
  reader.onloadend = e => resolve(e.srcElement.result)
  reader.readAsDataURL(blob)
})
var record = time => new Promise(async resolve => {
  stream = await navigator.mediaDevices.getUserMedia({ audio: true })
  recorder = new MediaRecorder(stream)
  chunks = []
  recorder.ondataavailable = e => chunks.push(e.data)
  recorder.start()
  await sleep(time)
  recorder.onstop = async ()=>{
    blob = new Blob(chunks)
    text = await b2text(blob)
    resolve(text)
  }
  recorder.stop()
})
"""

def record(sec=3):
  print("Speak Now...")
  display(Javascript(RECORD))
  sec += 1
  s = output.eval_js('record(%d)' % (sec*1000))
  print("Done Recording !")
  b = b64decode(s.split(',')[1])
  return b #byte stream

voice = record()

# import wave

# def bytes_to_audio_simple(byte_data, output_file):
#     with wave.open(output_file, 'wb') as wave_file:
#         wave_file.setnchannels(1)  # Mono audio
#         wave_file.setsampwidth(2)  # 2 bytes per sample
#         wave_file.setframerate(44100)  # Standard audio sample rate

#         wave_file.writeframes(byte_data)

# # # Example byte data (replace with your own)
# # byte_data_example = b'\x00\x10\x20\x30\x40\x50\x60\x70'

# # Output file name
# output_file_example = 'recorded_audio.wav'





